{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0595c3",
   "metadata": {},
   "source": [
    "## Anomaly Detection on Financial Support for each Strategic Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046b463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d0b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base path for input data files\n",
    "CURRENT_DIR = Path().resolve()\n",
    "DATA_BASE_PATH = CURRENT_DIR.parent / \"outputs\" / \"data_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0fb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path for the modeling data file\n",
    "output_dir = os.path.join(\"..\", \"outputs\", \"model_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70843e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../outputs/data_output/Financial_Cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7628183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ratio Features\n",
    "epsilon = 1e-6\n",
    "for year in range(2020, 2026):\n",
    "    df[f\"{year}_Exp_per_Req\"] = df[f\"{year} Expenditure\"] / (df[f\"{year} Required\"] + epsilon)\n",
    "    df[f\"{year}_Exp_per_Avail\"] = df[f\"{year} Expenditure\"] / (df[f\"{year} Available\"] + epsilon)\n",
    "    df[f\"{year}_Avail_per_Req\"] = df[f\"{year} Available\"] / (df[f\"{year} Required\"] + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89389f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Select features\n",
    "raw_cols = [f\"{year} {k}\" for year in range(2020, 2026) for k in [\"Required\", \"Available\", \"Expenditure\"]]\n",
    "agg_cols = ['Total required resources', 'Total available resources', 'Total expenditure resources']\n",
    "ratio_cols = [col for col in df.columns if \"_per_\" in col]\n",
    "\n",
    "num_features = df[raw_cols + agg_cols + ratio_cols].replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc715402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features to one-hot encode\n",
    "\n",
    "cat_cols = ['Country', 'Region', 'Theme', 'SP_Label', 'SDG Goals', 'Agencies']\n",
    "df_cat = pd.get_dummies(df[cat_cols].fillna(\"Unknown\"), drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37c265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "X = pd.concat([num_features, df_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "372dfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 2: Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d928efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Counts:\n",
      "Anomaly_LOF: 130\n",
      "Anomaly_IsolationForest: 130\n",
      "Anomaly_OneClassSVM: 290\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "# Models dictionary\n",
    "anomaly_models = {}\n",
    "\n",
    "# Model 1: Isolation Forest\n",
    "anomaly_models[\"IsolationForest\"] = IsolationForest(contamination=0.05, random_state=42)\n",
    "\n",
    "# Model 2: One-Class SVM\n",
    "anomaly_models[\"OneClassSVM\"] = OneClassSVM(nu=0.05, kernel='rbf', gamma='scale')\n",
    "\n",
    "# Model 3: Local Outlier Factor (fit_predict only, no separate fit)\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "df['Anomaly_LOF'] = lof.fit_predict(X_scaled)\n",
    "\n",
    "# Fit the remaining models\n",
    "for name, model in anomaly_models.items():\n",
    "    df[f'Anomaly_{name}'] = model.fit_predict(X_scaled)\n",
    "\n",
    "# Compare Anomaly Detection Results\n",
    "print(\"Anomaly Counts:\")\n",
    "for col in df.columns:\n",
    "    if \"Anomaly_\" in col:\n",
    "        n_anomalies = (df[col] == -1).sum()\n",
    "        print(f\"{col}: {n_anomalies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035969f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Silhouette Scores:\n",
      "Anomaly_LOF: 0.1227\n",
      "Anomaly_IsolationForest: -0.0085\n",
      "Anomaly_OneClassSVM: 0.1079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "print(\"\\nSilhouette Scores:\")\n",
    "for col in df.columns:\n",
    "    if \"Anomaly_\" in col:\n",
    "        try:\n",
    "            labels = df[col]\n",
    "            score = silhouette_score(X_scaled, labels)\n",
    "            print(f\"{col}: {score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{col}: Could not compute ({e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c5154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Fit LOF again to ensure it's reproducible here\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "df['SP_Anomaly_Flag'] = lof.fit_predict(X_scaled)\n",
    "\n",
    "# Map -1 to \"Yes\" (anomalous), 1 to \"No\"\n",
    "df['SP_Anomaly_Flag'] = df['SP_Anomaly_Flag'].map({-1: \"Yes\", 1: \"No\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdfbe218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(output_dir, \"anomaly_detection.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
